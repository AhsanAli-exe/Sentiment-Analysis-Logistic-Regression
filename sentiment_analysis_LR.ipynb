{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "007fcb19",
   "metadata": {},
   "source": [
    "# Sentiment Analysis using Logistic Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "761433ac",
   "metadata": {},
   "source": [
    "# Logistic Regression Theory\n",
    "\n",
    "**Logistic Regression** is perfect for binary classification (positive/negative sentiment).\n",
    "\n",
    "## How it works:\n",
    "1. **Linear Combination**: z = θ₀ + θ₁x₁ + θ₂x₂ + ... + θₙxₙ\n",
    "2. **Sigmoid Function**: σ(z) = 1 / (1 + e^(-z)) → maps to probability [0,1]\n",
    "3. **Decision**: If σ(z) ≥ 0.5 → Positive, else → Negative\n",
    "\n",
    "## Our Features:\n",
    "- x₁: Bias term (always 1)\n",
    "- x₂: Sum of positive word frequencies  \n",
    "- x₃: Sum of negative word frequencies\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "69e2aad7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from os import getcwd\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.corpus import twitter_samples\n",
    "from utils import process_tweet, build_freqs, extract_features\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "953d70cd",
   "metadata": {},
   "source": [
    "Train Test Split (80/20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d77ec9e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_tweets = twitter_samples.strings('positive_tweets.json')\n",
    "neg_tweets = twitter_samples.strings('negative_tweets.json')\n",
    "\n",
    "test_pos = pos_tweets[4000:]\n",
    "train_pos = pos_tweets[:4000]\n",
    "test_neg = neg_tweets[4000:]\n",
    "train_neg = neg_tweets[:4000]\n",
    "\n",
    "train_x = train_pos + train_neg\n",
    "test_x = test_pos + test_neg\n",
    "\n",
    "train_y = np.append(np.ones((len(train_pos),1)),np.zeros((len(train_neg),1)),axis=0)\n",
    "test_y = np.append(np.ones((len(test_pos),1)),np.zeros((len(test_neg),1)),axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ad08ac3b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisticRegression model created\n",
      "Model parameters: {'C': 1.0, 'class_weight': None, 'dual': False, 'fit_intercept': True, 'intercept_scaling': 1, 'l1_ratio': None, 'max_iter': 1000, 'multi_class': 'auto', 'n_jobs': None, 'penalty': 'l2', 'random_state': 42, 'solver': 'lbfgs', 'tol': 0.0001, 'verbose': 0, 'warm_start': False}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "model = LogisticRegression(\n",
    "    C=1.0,             # -> Regularization(Control overfitting)\n",
    "    max_iter=1000,     # ->  how many iterations to find optimal weights\n",
    "    random_state=42,    \n",
    "    solver='lbfgs'     # -> general purpose solver (can also use liblinear)\n",
    ")\n",
    "\n",
    "print(\"LogisticRegression model created\")\n",
    "print(f\"Model parameters: {model.get_params()}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94c3fb7d",
   "metadata": {},
   "source": [
    "Feature Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "20496f6f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Frequency dictionary built with 11397 word-sentiment pairs\n"
     ]
    }
   ],
   "source": [
    "freqs = build_freqs(train_x, train_y)\n",
    "print(f\"Frequency dictionary built with {len(freqs)} word-sentiment pairs\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fec489d",
   "metadata": {},
   "source": [
    "Feature Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b6cf699d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting features for training data\n",
      "Training features extracted: (8000, 3)\n",
      "Features -> [bias, positive_freq, negative_freq]\n",
      "example tweet features: [1.000e+00 3.133e+03 6.100e+01]\n"
     ]
    }
   ],
   "source": [
    "print(\"Extracting features for training data\")\n",
    "X_train = np.zeros((len(train_x),3))  #[bias,pos_freq,neg_freq]\n",
    "\n",
    "for i,tweet in enumerate(train_x):\n",
    "    processed_tweet = process_tweet(tweet)\n",
    "    features = extract_features(processed_tweet,freqs)\n",
    "    X_train[i,:] = features\n",
    "\n",
    "print(f\"Training features extracted: {X_train.shape}\")\n",
    "print(f\"Features -> [bias, positive_freq, negative_freq]\")\n",
    "print(f\"example tweet features: {X_train[0]}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6c2db1d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting features for test data\n",
      "Test features extracted: (2000, 3)\n"
     ]
    }
   ],
   "source": [
    "print(\"Extracting features for test data\")\n",
    "X_test = np.zeros((len(test_x), 3))\n",
    "\n",
    "for i,tweet in enumerate(test_x):\n",
    "    processed_tweet = process_tweet(tweet)\n",
    "    features = extract_features(processed_tweet,freqs)\n",
    "    X_test[i,:] = features\n",
    "\n",
    "print(f\"Test features extracted: {X_test.shape}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a431897a",
   "metadata": {},
   "source": [
    "Flattening for SciKit Learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "60b5ddf5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Labels prepared -> Train: (8000,),Test: (2000,)\n"
     ]
    }
   ],
   "source": [
    "y_train = train_y.flatten()\n",
    "y_test = test_y.flatten()\n",
    "print(f\"Labels prepared -> Train: {y_train.shape},Test: {y_test.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d194a67a",
   "metadata": {},
   "source": [
    "Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6023834a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model training completed\n"
     ]
    }
   ],
   "source": [
    "model.fit(X_train, y_train)\n",
    "print(\"Model training completed\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f01a91a6",
   "metadata": {},
   "source": [
    "Accuracy Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f422c4fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy: 0.9942 (99.42%)\n",
      "Test Accuracy: 0.9950 (99.50%)\n"
     ]
    }
   ],
   "source": [
    "y_train_pred = model.predict(X_train)\n",
    "train_accuracy = accuracy_score(y_train,y_train_pred)\n",
    "y_test_pred = model.predict(X_test)\n",
    "test_accuracy = accuracy_score(y_test, y_test_pred)\n",
    "\n",
    "print(f\"Training Accuracy: {train_accuracy:.4f} ({train_accuracy*100:.2f}%)\")\n",
    "print(f\"Test Accuracy: {test_accuracy:.4f} ({test_accuracy*100:.2f}%)\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d1e5e73",
   "metadata": {},
   "source": [
    "Making Predictions on New Tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f449627d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tweet: 'I love this movie! It's absolutely amazing! #movielife #happy'\n",
      "Sentiment: positive (Probability: 0.968)\n",
      "Tweet: 'This is the worst day ever #hate . I hate everything '\n",
      "Sentiment: negative (Probability: 0.496)\n",
      "Tweet: 'The weather is okay today'\n",
      "Sentiment: positive (Probability: 0.543)\n",
      "Tweet: 'Happy birthday! Hope you have a wonderful day!'\n",
      "Sentiment: positive (Probability: 0.929)\n",
      "Tweet: 'I'm so disappointed with this product. Terrible quality. #disappointed https://t.co/1234567890'\n",
      "Sentiment: positive (Probability: 0.567)\n"
     ]
    }
   ],
   "source": [
    "def predict_sentiment(tweet,model,freqs):\n",
    "    processed_tweet = process_tweet(tweet)\n",
    "    features = extract_features(processed_tweet,freqs)\n",
    "    prediction = model.predict(features)[0]\n",
    "    probability = model.predict_proba(features)[0][1] \n",
    "    return prediction,probability,features[0]\n",
    "\n",
    "\n",
    "test_tweets = [\n",
    "    \"I love this movie! It's absolutely amazing! #movielife #happy\",\n",
    "    \"This is the worst day ever #hate . I hate everything \",\n",
    "    \"The weather is okay today\",\n",
    "    \"Happy birthday! Hope you have a wonderful day!\",\n",
    "    \"I'm so disappointed with this product. Terrible quality. #disappointed https://t.co/1234567890\"\n",
    "]\n",
    "\n",
    "for tweet in test_tweets:\n",
    "    prediction,probability,features = predict_sentiment(tweet, model, freqs)\n",
    "    sentiment = \"positive\" if prediction == 1 else \"negative\"\n",
    "    \n",
    "    \n",
    "    print(f\"Tweet: '{tweet}'\")\n",
    "    print(f\"Sentiment: {sentiment} (Probability: {probability:.3f})\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
